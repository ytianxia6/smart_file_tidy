# ============================================
# 智能文件整理助手 - 自定义API配置示例
# ============================================
# 
# 使用说明：
# 1. 复制此文件为 .env (注意前面有个点)
#    Windows: copy env.custom.example .env
#    Linux/Mac: cp env.custom.example .env
# 2. 根据您使用的服务选择对应配置
# 3. 取消注释并填写实际的API密钥
# 4. 运行 python examples/test_custom_api.py 验证配置
#
# ============================================

# AI提供商选择（必填）
DEFAULT_AI_PROVIDER=custom

# ============================================
# 方案1: DeepSeek（推荐 - 高性价比）
# ============================================
CUSTOM_API_BASE_URL=https://api.deepseek.com/v1
CUSTOM_API_KEY=sk-your-deepseek-api-key-here
CUSTOM_API_MODEL=deepseek-chat

# ============================================
# 方案2: 阿里云通义千问 (DashScope)
# ============================================
# CUSTOM_API_BASE_URL=https://dashscope.aliyuncs.com/compatible-mode/v1
# CUSTOM_API_KEY=sk-your-dashscope-api-key-here
# CUSTOM_API_MODEL=qwen-plus
# 
# 可选模型:
# - qwen-turbo (轻量快速)
# - qwen-plus (平衡性能)
# - qwen-max (最强性能)

# ============================================
# 方案3: Moonshot AI (月之暗面)
# ============================================
# CUSTOM_API_BASE_URL=https://api.moonshot.cn/v1
# CUSTOM_API_KEY=sk-your-moonshot-api-key-here
# CUSTOM_API_MODEL=moonshot-v1-8k
#
# 可选模型:
# - moonshot-v1-8k (8K上下文)
# - moonshot-v1-32k (32K上下文)
# - moonshot-v1-128k (128K上下文)

# ============================================
# 方案4: 智谱AI (GLM)
# ============================================
# CUSTOM_API_BASE_URL=https://open.bigmodel.cn/api/paas/v4
# CUSTOM_API_KEY=your-zhipu-api-key-here
# CUSTOM_API_MODEL=glm-4
#
# 可选模型:
# - glm-4 (GLM-4标准版)
# - glm-4-air (轻量版)
# - glm-4-flash (快速版)

# ============================================
# 方案5: SiliconFlow (多种开源模型)
# ============================================
# CUSTOM_API_BASE_URL=https://api.siliconflow.cn/v1
# CUSTOM_API_KEY=sk-your-siliconflow-api-key-here
# CUSTOM_API_MODEL=Qwen/Qwen2-7B-Instruct
#
# 热门模型:
# - Qwen/Qwen2-7B-Instruct (通义千问)
# - deepseek-ai/DeepSeek-V2-Chat (DeepSeek)
# - meta-llama/Meta-Llama-3-8B-Instruct (Llama 3)

# ============================================
# 方案6: 本地部署 (vLLM/Ollama/其他)
# ============================================
# CUSTOM_API_BASE_URL=http://localhost:8000/v1
# CUSTOM_API_KEY=sk-no-key-required
# CUSTOM_API_MODEL=your-local-model-name

# ============================================
# 高级配置（可选）
# ============================================
# 这些配置在 config/default_config.yaml 中设置，
# 通常不需要在 .env 中修改

# LangChain Agent配置
# - 详细日志: langchain.agent.verbose (true/false)
# - 最大迭代: langchain.agent.max_iterations (默认15)
# - 超时时间: langchain.agent.max_execution_time (默认300秒)

# 工具配置
# - 扫描文件数: langchain.tools.file_scanner.max_files (默认1000)
# - 内容分析长度: langchain.tools.file_analyzer.max_content_size (默认2000)

# ============================================
# 验证配置
# ============================================
# 配置完成后，运行以下命令验证:
# python examples/test_custom_api.py
#
# 或者直接测试:
# smart-tidy chat
